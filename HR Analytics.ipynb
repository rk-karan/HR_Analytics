{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for custom scaler\n",
    "#for scaling cselected columns in a dataframe\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class CustomScaler(BaseEstimator,TransformerMixin): \n",
    "        \n",
    "    def __init__(self,columns,copy=True,with_mean=True,with_std=True):\n",
    "        self.scaler = StandardScaler(copy,with_mean,with_std)\n",
    "        self.columns = columns\n",
    "        self.mean_ = None\n",
    "        self.var_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X[self.columns], y)\n",
    "        self.mean_ = np.mean(X[self.columns])\n",
    "        self.var_ = np.var(X[self.columns])\n",
    "        return self\n",
    "    \n",
    "    #\n",
    "    def transform(self, X, y=None, copy=None):\n",
    "        \n",
    "        init_col_order = X.columns\n",
    "        X_scaled = pd.DataFrame(self.scaler.transform(X[self.columns]), columns=self.columns)\n",
    "        X_not_scaled = X.loc[:,~X.columns.isin(self.columns)]\n",
    "        return pd.concat([X_not_scaled, X_scaled], axis=1)[init_col_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required csv\n",
    "raw_dataset=pd.read_csv('HR_train_set.csv')\n",
    "saved_raw_dataset=raw_dataset\n",
    "\n",
    "#the mode and median of the education column is Bacheclor's and hence we impute the missing values with Bachelor's\n",
    "raw_dataset['education']=raw_dataset['education'].fillna(\"Bachelor's\")\n",
    "\n",
    "#for imputing previous years rating we used mode.\n",
    "#mode of the dataset=3\n",
    "\n",
    "#raw_dataset['previous_year_rating']=raw_dataset['previous_year_rating'].fillna(raw_dataset['previous_year_rating'].mean())\n",
    "raw_dataset['previous_year_rating']=raw_dataset['previous_year_rating'].fillna(3.0)\n",
    "\n",
    "#saving the dataset with no null values\n",
    "df_nonull=raw_dataset\n",
    "\n",
    "#one hot encoding for departments\n",
    "df_nonull=pd.concat([df_nonull,pd.get_dummies(df_nonull['department'], prefix='dept', drop_first=True)], axis=1)\n",
    "df_nonull.drop(['department'], axis=1, inplace=True)\n",
    "\n",
    "#binary label encoding for gender\n",
    "df_nonull['gender']=df_nonull['gender'].map({'f':0, 'm':1})\n",
    "\n",
    "#label encoding for education\n",
    "df_nonull['education']=df_nonull['education'].map({\"Master's & above\":2, \"Bachelor's\":1, 'Below Secondary':0})\n",
    "\n",
    "#one hot encoding for recruitment_channel\n",
    "df_nonull=pd.concat([df_nonull,pd.get_dummies(df_nonull['recruitment_channel'], prefix='recruit', drop_first=False)], axis=1)\n",
    "df_nonull.drop(['recruitment_channel'], axis=1, inplace=True)\n",
    "df_nonull.drop(['recruit_other'], axis=1, inplace=True)\n",
    "\n",
    "#label encoding for region\n",
    "df_nonull['region']=df_nonull['region'].map({'region_7':7, 'region_22':22, 'region_19':19, 'region_23':23, 'region_26':26,\n",
    "                                             'region_2':2, 'region_20':20, 'region_34':34, 'region_1':1, 'region_4':4,\n",
    "                                             'region_29':29, 'region_31':31, 'region_15':15, 'region_14':14, 'region_11':11,\n",
    "                                             'region_5':5, 'region_28':28, 'region_17':17, 'region_13':13, 'region_16':16,\n",
    "                                             'region_25':25, 'region_10':10, 'region_27':27, 'region_30':30, 'region_12':12,\n",
    "                                             'region_21':21, 'region_8':8, 'region_32':32, 'region_6':6, 'region_33':33,\n",
    "                                             'region_24':24, 'region_3':3, 'region_9':9, 'region_18':18})\n",
    "\n",
    "#dropping employee id\n",
    "df_nonull.drop(['employee_id'],axis=1,inplace=True)\n",
    "\n",
    "#defining targets and inputs\n",
    "targets=df_nonull['is_promoted']\n",
    "df_nonull.drop(['is_promoted'],axis=1,inplace=True)\n",
    "unscaled_inputs=df_nonull\n",
    "\n",
    "#custom scalling the required features\n",
    "columns_to_omit = ['gender', 'KPIs_met >80%', 'awards_won?', 'dept_Finance',\n",
    "                   'dept_HR', 'dept_Legal', 'dept_Operations', 'dept_Procurement',\n",
    "                   'dept_R&D', 'dept_Sales & Marketing', 'dept_Technology',\n",
    "                   'recruit_referred', 'recruit_sourcing', 'education']\n",
    "columns_to_scale = [x for x in unscaled_inputs.columns.values if x not in columns_to_omit]\n",
    "\n",
    "HR_scaler = CustomScaler(columns_to_scale)\n",
    "HR_scaler.fit(unscaled_inputs)\n",
    "scaled_inputs = HR_scaler.transform(unscaled_inputs)\n",
    "\n",
    "#splitting the targets and features into train and test set\n",
    "#x_train, x_test, y_train, y_test=train_test_split(scaled_inputs, targets, test_size=0.2, random_state=42)\n",
    "x_train=scaled_inputs\n",
    "y_train=targets\n",
    "\n",
    "#applying logistic regression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "\n",
    "#predicting values\n",
    "y_hat_train = logisticRegr.predict(x_train)\n",
    "#y_hat_test = logisticRegr.predict(x_test)\n",
    "\n",
    "#scores\n",
    "#score_test = logisticRegr.score(x_test, y_test)\n",
    "score_train = logisticRegr.score(x_train, y_train)\n",
    "\n",
    "print(score_train)\n",
    "#print(score_test)\n",
    "\n",
    "#creating a summary table to know about the importances of each feature\n",
    "    #feature_name = unscaled_inputs.columns.values\n",
    "    #summary_table = pd.DataFrame (columns=['Feature name'], data = feature_name)\n",
    "    #summary_table['Coefficient'] = np.transpose(logisticRegr.coef_)\n",
    "    #summary_table.index = summary_table.index + 1\n",
    "    #summary_table.loc[0] = ['Intercept', logisticRegr.intercept_[0]]\n",
    "    #summary_table = summary_table.sort_index()\n",
    "    #summary_table['Odds_ratio'] = np.exp(summary_table.Coefficient)\n",
    "    #summary_table=summary_table.sort_values('Odds_ratio', ascending=False)\n",
    "    #summary_table\n",
    "\n",
    "#assembling the prediction in the form of a dataframe\n",
    "#results = pd.DataFrame (columns=['employee_id'], data = raw_dataset['employee_id'])\n",
    "#results['is_promoted'] = np.transpose(y_hat_train)\n",
    "#results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data=pd.read_csv('HR_test_set.csv')\n",
    "\n",
    "testing_data['education']=testing_data['education'].fillna(\"Bachelor's\")\n",
    "testing_data['previous_year_rating']=testing_data['previous_year_rating'].fillna(3.0)\n",
    "\n",
    "testing_data=pd.concat([testing_data,pd.get_dummies(testing_data['department'], prefix='dept', drop_first=True)], axis=1)\n",
    "testing_data.drop(['department'], axis=1, inplace=True)\n",
    "\n",
    "testing_data['gender']=testing_data['gender'].map({'f':0, 'm':1})\n",
    "testing_data['education']=testing_data['education'].map({\"Master's & above\":2, \"Bachelor's\":1, 'Below Secondary':0})\n",
    "\n",
    "testing_data=pd.concat([testing_data,pd.get_dummies(testing_data['recruitment_channel'], prefix='recruit', drop_first=False)], axis=1)\n",
    "testing_data.drop(['recruitment_channel'], axis=1, inplace=True)\n",
    "testing_data.drop(['recruit_other'], axis=1, inplace=True)\n",
    "\n",
    "testing_data['region']=testing_data['region'].map({'region_7':7, 'region_22':22, 'region_19':19, 'region_23':23, 'region_26':26,\n",
    "                                             'region_2':2, 'region_20':20, 'region_34':34, 'region_1':1, 'region_4':4,\n",
    "                                             'region_29':29, 'region_31':31, 'region_15':15, 'region_14':14, 'region_11':11,\n",
    "                                             'region_5':5, 'region_28':28, 'region_17':17, 'region_13':13, 'region_16':16,\n",
    "                                             'region_25':25, 'region_10':10, 'region_27':27, 'region_30':30, 'region_12':12,\n",
    "                                             'region_21':21, 'region_8':8, 'region_32':32, 'region_6':6, 'region_33':33,\n",
    "                                             'region_24':24, 'region_3':3, 'region_9':9, 'region_18':18})\n",
    "\n",
    "unscaled_inputs_final=testing_data.drop(['employee_id'],axis=1)\n",
    "scaled_inputs_final = HR_scaler.transform(unscaled_inputs_final)\n",
    "\n",
    "y_test= logisticRegr.predict(scaled_inputs_final)\n",
    "\n",
    "\n",
    "results = pd.DataFrame (columns=['employee_id'], data =testing_data['employee_id'])\n",
    "results['is_promoted'] = np.transpose(y_test)\n",
    "#results.to_csv('results.csv', index=False)\n",
    "#results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
